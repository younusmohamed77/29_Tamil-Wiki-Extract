{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f8591d-cbd9-4cf9-a9f9-e5b1b58e8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "from io import StringIO\n",
    "from multiprocessing import Queue, Process, cpu_count\n",
    "from timeit import default_timer\n",
    "\n",
    "# Adjust the regex pattern as raw strings to avoid escape sequence issues\n",
    "tagRE = re.compile(r'(.*?)<(/?\\w+)[^>]*>(?:([^<]*)(<.*?>)?)?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db2205f9-ed0d-414e-b61b-b2de9975ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextFile:\n",
    "    filesPerDir = 100\n",
    "\n",
    "    def __init__(self, path_name):\n",
    "        self.path_name = path_name\n",
    "        self.dir_index = -1\n",
    "        self.file_index = -1\n",
    "\n",
    "    def next(self):\n",
    "        self.file_index = (self.file_index + 1) % NextFile.filesPerDir\n",
    "        if self.file_index == 0:\n",
    "            self.dir_index += 1\n",
    "        dirname = self._dirname()\n",
    "        if not os.path.isdir(dirname):\n",
    "            os.makedirs(dirname)\n",
    "        return self._filepath()\n",
    "\n",
    "    def _dirname(self):\n",
    "        char1 = self.dir_index % 26\n",
    "        char2 = int(self.dir_index / 26) % 26\n",
    "        return os.path.join(self.path_name, '%c%c' % (ord('A') + char2, ord('A') + char1))\n",
    "\n",
    "    def _filepath(self):\n",
    "        return '%s/wiki_%02d' % (self._dirname(), self.file_index)\n",
    "\n",
    "\n",
    "class OutputSplitter:\n",
    "    def __init__(self, nextFile, max_file_size=0, compress=True):\n",
    "        \"\"\"\n",
    "        :param nextFile: a NextFile object from which to obtain filenames.\n",
    "        :param max_file_size: the maximum size of each file.\n",
    "        :param compress: whether to write data with bzip compression.\n",
    "        \"\"\"\n",
    "        self.nextFile = nextFile\n",
    "        self.compress = compress\n",
    "        self.max_file_size = max_file_size\n",
    "        self.file = self.open(self.nextFile.next())\n",
    "\n",
    "    def reserve(self, size):\n",
    "        if self.file.tell() + size > self.max_file_size:\n",
    "            self.close()\n",
    "            self.file = self.open(self.nextFile.next())\n",
    "\n",
    "    def write(self, data):\n",
    "        self.reserve(len(data))\n",
    "        # If compressing, write as bytes; otherwise, write as string\n",
    "        if self.compress:\n",
    "            self.file.write(data.encode('utf-8'))  # Encode to bytes for bz2\n",
    "        else:\n",
    "            self.file.write(data)\n",
    "\n",
    "    def close(self):\n",
    "        self.file.close()\n",
    "\n",
    "    def open(self, filename):\n",
    "        if self.compress:\n",
    "            return bz2.BZ2File(filename + '.bz2', 'wb')  # Open in binary mode for bz2\n",
    "        else:\n",
    "            return open(filename, 'w', encoding='utf-8')  # Open as text if not compressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e51cee0-e3a4-45e4-b948-166724da3c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_templates(file):\n",
    "    templates = {}\n",
    "    page = []\n",
    "    inText = False\n",
    "    for line in file:\n",
    "        if '<' not in line:\n",
    "            if inText:\n",
    "                page.append(line)\n",
    "            continue\n",
    "        m = tagRE.search(line)\n",
    "        if not m:\n",
    "            continue\n",
    "        tag = m.group(2)\n",
    "        if tag == 'page':\n",
    "            page = []\n",
    "        elif tag == 'title':\n",
    "            title = m.group(3)\n",
    "        elif tag == 'text':\n",
    "            inText = True\n",
    "            line = line[m.start(3):m.end(3)]\n",
    "            page.append(line)\n",
    "            if m.lastindex == 4:\n",
    "                inText = False\n",
    "        elif tag == '/text':\n",
    "            if m.group(1):\n",
    "                page.append(m.group(1))\n",
    "            inText = False\n",
    "        elif inText:\n",
    "            page.append(line)\n",
    "        elif tag == '/page':\n",
    "            templates[title] = page\n",
    "            page = []\n",
    "    return templates\n",
    "\n",
    "\n",
    "def process_pages(input_file, output_directory, max_file_size=100*1024, compress=True):\n",
    "    next_file = NextFile(output_directory)\n",
    "    output = OutputSplitter(next_file, max_file_size, compress)\n",
    "\n",
    "    article_count = 0  # Initialize article counter\n",
    "    start_time = time.time()  # Record start time for progress tracking\n",
    "\n",
    "    # Open the XML file directly without bz2 compression\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        page = []\n",
    "        for line in file:\n",
    "            if '<' not in line:\n",
    "                if page:\n",
    "                    page.append(line)\n",
    "                continue\n",
    "            m = tagRE.search(line)\n",
    "            if not m:\n",
    "                continue\n",
    "            tag = m.group(2)\n",
    "            if tag == 'page':\n",
    "                page = []\n",
    "            elif tag == 'title':\n",
    "                title = m.group(3)\n",
    "            elif tag == 'text':\n",
    "                line = line[m.start(3):m.end(3)]\n",
    "                page.append(line)\n",
    "                if m.lastindex == 4:\n",
    "                    output.write(\" \".join(page))\n",
    "                    page = []\n",
    "                    article_count += 1  # Increment article counter\n",
    "            elif tag == '/text' and page:\n",
    "                output.write(\" \".join(page))\n",
    "                page = []\n",
    "                article_count += 1  # Increment article counter\n",
    "            elif tag == '/page':\n",
    "                page = []\n",
    "                article_count += 1  # Increment article counter\n",
    "\n",
    "            # Log progress every 100000 articles\n",
    "            if article_count % 100000 == 0:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print(f\"Processed {article_count} articles in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "    # Final log for total articles processed\n",
    "    print(f\"Completed processing {article_count} articles in {time.time() - start_time:.2f} seconds\")\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce93230e-0261-452b-afb2-9f4dc436a0b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 0 articles in 0.00 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 100000 articles in 27.28 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 200000 articles in 44.71 seconds\n",
      "Processed 300000 articles in 72.76 seconds\n",
      "Processed 300000 articles in 72.76 seconds\n",
      "Processed 300000 articles in 72.76 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 400000 articles in 99.34 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Processed 500000 articles in 130.06 seconds\n",
      "Completed processing 569055 articles in 149.25 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set the paths to your input and output\n",
    "input_file = r\"C:\\Users\\Hi\\My Works\\My Py Scripts\\Git Repos\\29_Tamil Wiki\\tawiki-20241101-pages-articles-multistream.xml\"\n",
    "output_directory = r\"C:/Users/Hi/My Works/My Py Scripts/Git Repos/29_Tamil Wiki/extracted_articles\"\n",
    "\n",
    "# Process the Wikipedia dump file\n",
    "process_pages(input_file, output_directory, max_file_size=10*1024*1024, compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3612da0-ed65-4a41-99a1-52dbfcf0b206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
